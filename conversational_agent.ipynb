{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab24823-90c5-4229-a5ad-19f46dcf5999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9972a2fe-afb2-46e7-837c-a397e4cf90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv(), override=True)\n",
    "api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c5647-cb6a-4d4a-a392-2c6cdee313fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " HELLO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! How can I help you today?\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " whats your name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have a name. I'm a large language model, an AI.  I'm here to assist you with information and tasks.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is an LLM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM stands for **Large Language Model**.  It's a type of artificial intelligence (AI) that's been trained on a massive amount of text data. This training allows it to understand, generate, and manipulate human language in various ways.  Think of it like a super-powered language student that has read almost everything ever written.\n",
      "\n",
      "Here's a breakdown of key characteristics:\n",
      "\n",
      "* **Large:**  This refers to the sheer size of the model, both in terms of\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " how large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"large\" in LLM refers to two main aspects:\n",
      "\n",
      "* **Huge Datasets:** LLMs are trained on incredibly vast datasets of text and code, often containing petabytes of data.  This massive dataset allows them to learn complex patterns, grammar, and relationships between words and concepts.  Think of it like reading the entire internet, multiple times over.\n",
      "\n",
      "* **Billions of Parameters:**  LLMs have billions, even trillions, of parameters. These parameters are\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " u mean like a function has paramters, u were trained on data that has trillion parameters or feature variables. am i right?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're on the right track, but not quite.  The parameters aren't features *of the data* itself, but rather adjustable values *within the model* that are learned during the training process.  They determine the strength of connections between different parts of the model and influence how it processes and generates text.\n",
      "\n",
      "Think of it like this:\n",
      "\n",
      "* **Data:** The text and code used for training are like the textbook for the LLM.\n",
      "* **Parameters:** These are\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " more\n"
     ]
    }
   ],
   "source": [
    "generation_config = {\n",
    "  \"temperature\": 0.4,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 100,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-002\", generation_config=generation_config)\n",
    "chat_session = model.start_chat(history=[])\n",
    "\n",
    "while((z := input().strip().lower()) != 'exit'):\n",
    "    response = chat_session.send_message(z)\n",
    "    print(response.text)\n",
    "    print('-'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682e16d-31cc-433d-8ad0-b6c055a346ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
